# Evaluation Results

## Training Evaluation

The model was evaluated on two splits:

- **Eval** (145 examples): Same collection schemas as training, different intents
- **Held-out** (368 examples): 3 collection schemas the model never saw during training (`museum_exhibits`, `weather_stations`, `fleet_vehicles`)

### Comparison: Baseline vs Fine-tuned

| Model | Split | Syntax | Operators | Fields | Overall |
|---|---|---|---|---|---|
| Qwen 7B zero-shot | eval | 51.0% | 51.0% | 40.0% | 40.0% |
| Qwen 7B zero-shot | held-out | 53.8% | 53.5% | 39.9% | 39.9% |
| **Qwen 7B + LoRA r=8** | **eval** | **100.0%** | **100.0%** | **100.0%** | **100.0%** |
| **Qwen 7B + LoRA r=8** | **held-out** | **98.9%** | **98.9%** | **98.9%** | **98.9%** |

CodeLlama 7B was also tested but collapsed to 0% after fine-tuning (both r=8 and r=16).

## Generalization to Unseen Schemas

The model was trained on synthetic schemas (e-commerce, healthcare, IoT, etc.) but generalizes to completely new domains and collection structures it has never seen. The examples below were generated by the deployed inference service against schemas that do not exist in the training data.

### Example 1: E-commerce Orders

**Schema**: `orders` collection with fields `order_id`, `total`, `status` (enum: pending/shipped/delivered), `created_at`

**Intent**: "Find all pending orders"

```json
{"type": "find", "filter": {"status": "pending"}}
```
*Latency: 438ms*

The model correctly maps the enum value "pending" to a filter on the `status` field.

---

### Example 2: Aggregation with Match

**Schema**: Same `orders` collection

**Intent**: "What is the average total of delivered orders"

```json
{
  "type": "aggregate",
  "pipeline": [
    {"$match": {"status": "delivered"}},
    {"$avg": "$total"}
  ]
}
```
*Latency: 788ms*

The model chooses `aggregate` over `find` and correctly chains a `$match` stage to filter delivered orders before computing the average.

---

### Example 3: Group + Sort (HR Domain)

**Schema**: `employees` collection with fields `name`, `department`, `salary`, `hire_date`, `active` — a domain that does not exist in training data.

**Intent**: "Show total salary by department sorted by highest first"

```json
{
  "type": "aggregate",
  "pipeline": [
    {"$group": {"_id": "$department", "total": {"$sum": "$salary"}}},
    {"$sort": {"total": -1}}
  ]
}
```
*Latency: 1,112ms*

The model has never seen an HR schema. It reads the field names and types, understands that `department` is a category suitable for grouping and `salary` is a measure suitable for summing, and builds a correct `$group` + `$sort` pipeline.

---

### Example 4: Find with Sort + Limit (HR Domain)

**Schema**: Same `employees` collection

**Intent**: "Find the highest paid employee in engineering"

```json
{
  "type": "find",
  "filter": {"department": "engineering"},
  "sort": {"salary": -1},
  "limit": 1
}
```
*Latency: 808ms*

The model correctly interprets "highest paid" as descending sort on `salary` with `limit: 1`, and "in engineering" as a filter on `department`. It chooses `find` over `aggregate` because no grouping or computation is needed.

---

## What the Model Learns

The model does not memorize query patterns for specific schemas. Instead, it learns to:

1. **Read the schema** — field names, types, roles (identifier, measure, timestamp, enum), and allowed enum values
2. **Interpret the intent** — identify what operation is needed (filter, group, sort, count, average)
3. **Choose the query type** — `find` for simple lookups, `aggregate` for computations
4. **Compose valid MongoDB syntax** — correct nesting of operators, proper field references, valid JSON structure
5. **Respect constraints** — only use allowed operators, only reference fields that exist in the schema

This is demonstrated by the 98.9% accuracy on held-out schemas that were never part of training, and by the examples above where the model generates correct queries for completely novel domains (HR, e-commerce) that it was never trained on.
